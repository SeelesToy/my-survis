[
  {
    "title": "Horus: A Modular GPU Emulator Framework",
    "authors": "A. Elhelw and Sreepathi Pai",
    "year": "2020",
    "doi": "10.1109/ISPASS48437.2020.00020",
    "abstract": "Graphics Processing Units (GPUs) are widely used to run general-purpose computing workloads. Three approaches currently exist to observe the dynamic behaviour of these workloads: real hardware, architectural simulators, and functional simulators (or emulators). However, the rapid evolution of GPU hardware and software stacks means that, in reality, using hardware is the only option to study current GPU workloads. Unfortunately, GPU toolchain support for advanced characterization capabilities is still far behind CPU toolchains like Pin. In this paper, we present an early glimpse of Horus, an emulator for NVIDIA GPUs. Although it is not the first such emulator, Horus is being engineered using a novel methodology to keep pace with the rapid changes in GPU hardware. Horus is highly modular, and is the first to utilize a specially designed DSL for specifying formal semantics for GPU instruction sets (NVIDIA PTX). A semantics compiler uses these semantics to generate the emulator. Horus also features a well-defined interface by which utility functions \u2013 instrumentation, new instruction support, analysis tools \u2013 can be coupled with the main emulator to increase reuse while studying the dynamic behaviour of GPU kernels. Horus is now mature enough to run all the Polybench and Rodinia benchmarks correctly.",
    "keywords": [
      "functional simulator",
      "formal semantics",
      "GPU",
      "instrumentation"
    ]
  },
  {
    "title": "Effective Profiling for Data-Intensive GPU Programs: Work-in-Progress",
    "authors": "Hwiwon Kim and Hyunjune Kim and Hwansoo Han",
    "year": "2020",
    "doi": "10.1109/CASES51649.2020.9243727",
    "abstract": "GPU profilers have been successfully used to analyze bottlenecks and slowdowns of GPU programs. Several instrumentation tools for profiling GPU binaries are introduced, but these tools take little consideration into GPU architectures. In this paper, we investigate common factors of performance degradation on existing GPU profilers and provide design guide to improve the performance.",
    "keywords": [
      "GPU",
      "CUDA",
      "Profiler",
      "Optimization"
    ]
  },
  {
    "title": "cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network Library, Based on OpenCL",
    "authors": "Hugh Perkins",
    "year": "2016",
    "doi": "",
    "abstract": "This paper presents cltorch, a hardware-agnostic backend for the Torch neural network framework. cltorch enables training of deep neural networks on GPUs from diverse hardware vendors, including AMD, NVIDIA, and Intel. cltorch contains sufficient implementation to run models such as AlexNet, VGG, Overfeat, and GoogleNet. It is written using the OpenCL language, a portable compute language, governed by the Khronos Group. cltorch is the top-ranked hardware-agnostic machine learning framework on Chintala's convnet-benchmarks page.",
    "keywords": [
      "GPU",
      "OpenCL",
      "Parallel",
      "Deep Neural Networks",
      "MachineLearning",
      "Convolution"
    ]
  },
  {
    "title": "Evaluating CUDA Portability with HIPCL and DPCT",
    "authors": "Zheming Jin and J. Vetter",
    "year": "2021",
    "doi": "10.1109/IPDPSW52791.2021.00065",
    "abstract": "HIPCL is expanding the scope of the CUDA portability route from an AMD platform to an OpenCL platform. In the meantime, the Intel DPC++ Compatibility Tool (DPCT) is migrating a CUDA program to a data parallel C++ (DPC++) program. Towards the goal of portability enhancement, we evaluate the performance of the CUDA applications from Rodinia, SHOC, and proxy applications ported using HIPCL and DPCT on Intel GPUs. After profiling the ported programs, we aim to understand their performance gaps, and optimize codes converted by DPCT to improve their performance. The open-source repository for the CUDA, HIP, and DPCT programs will be useful for the development of a translator.",
    "keywords": [
      "CUDA",
      "HIP",
      "OpenCL",
      "DPC++",
      "CUDA Portability"
    ]
  },
  {
    "title": "Correctly Treating Synchronizations in Compiling Fine-Grained SPMD-Threaded Programs for CPU",
    "authors": "Ziyu Guo and E. Zhang and Xipeng Shen",
    "year": "2011",
    "doi": "10.1109/PACT.2011.62",
    "abstract": "Automatic compilation for multiple types of devices is important, especially given the current trends towards heterogeneous computing. This paper concentrates on some issues in compiling fine-grained SPMD-threaded code (e.g., GPU CUDA code) for multicore CPUs. It points out some correctness pitfalls in existing techniques, particularly in their treatment to implicit synchronizations. It then describes a systematic dependence analysis specially designed for handling implicit synchronizations in SPMD-threaded programs. By unveiling the relations between inter-thread data dependences and correct treatment to synchronizations, it presents a dependence-based solution to the problem. Experiments demonstrate that the proposed techniques can resolve the correctness issues in existing compilation techniques, and help compilers produce correct and efficient translation results.",
    "keywords": [
      "GPU",
      "CUDA",
      "GPU-to-CPU Translation",
      "Implicit Synchronizations",
      "Dependence Analysis",
      "SPMD-Translation"
    ]
  },
  {
    "title": "Full-System Simulation of Mobile CPU/GPU Platforms",
    "authors": "Kuba Kaszyk and Harry Wagstaff and T. Spink and Bj\u00f6rn Franke and M. O\u2019Boyle and Bruno Bodin and Henrik Uhrenholt",
    "year": "2019",
    "doi": "10.1109/ISPASS.2019.00015",
    "abstract": "Graphics Processing Units (GPUs) critically rely on a complex system software stack comprising kernel- and user-space drivers and Just-in-time (JIT) compilers. Yet, existing GPU simulators typically abstract away details of the software stack and GPU instruction set. Partly, this is because GPU vendors rarely release sufficient information about their latest GPU products. However, this is also due to the lack of an integrated CPU/GPU simulation framework, which is complete and powerful enough to drive the complex GPU software environment. This has led to a situation where research on GPU architectures and compilers is largely based on outdated or greatly simplified architectures and software stacks, undermining the validity of the generated results. In this paper we develop a full-system system simulation environment for a mobile platform, which enables users to run a complete and unmodified software stack for a state-of-the-art mobile Arm CPU and Mali-G71 GPU powered device. We validate our simulator against a hardware implementation and Arm's stand-alone GPU simulator, achieving 100% architectural accuracy across all available toolchains. We demonstrate the capability of our GPU simulation framework by optimizing an advanced Computer Vision application using simulated statistics unavailable with other simulation approaches or physical GPU implementations. We demonstrate that performance optimizations for desktop GPUs trigger bottlenecks on mobile GPUs, and show the importance of efficient memory use.",
    "keywords": [
      "Computer simulation"
    ]
  },
  {
    "title": "A Virtual GPU as Developer-Friendly OpenMP Offload Target",
    "authors": "A. Patel and Shilei Tian and J. Doerfert and B. Chapman",
    "year": "2021",
    "doi": "10.1145/3458744.3473356",
    "abstract": "While parallel programming is hard, programming accelerators has always been even more complicated. One fundamental reason is the lack of mature tooling that can be used to inspect a program that executes on two different architectures. As GPU software stacks of different vendors provide vastly different experience for developers, it is clear that the gold standard for debugging is still host (CPU) execution with its myriad of mature tooling options. In this work we present a virtual GPU (VGPU) OpenMP offloading target that allows to emulate a GPU execution environment on the host. In contrast to classical \u201chost offloading\u201d, the VGPU target reuses the same execution model, compilation paths, and runtimes as a physical GPU. While this execution mode is not able to perform as good as host-specific compilation, runtimes, and execution, it provides the developor with a more accurate stand-in for GPU offloading that is still amendable to existing host tooling.",
    "keywords": [
      "LLVM",
      "OpenMP",
      "accelerator offloading",
      "GPU",
      "debugging"
    ]
  },
  {
    "title": "Efficient Instrumentation of GPGPU Applications Using Information Flow Analysis and Symbolic Execution",
    "authors": "N. Farooqui and K. Schwan and S. Yalamanchili",
    "year": "2014",
    "doi": "10.1145/2576779.2576782",
    "abstract": "Dynamic instrumentation of GPGPU binaries makes possible real-time introspection methods for performance debugging, correctness checks, workload characterization, and runtime optimization. Such instrumentation involves inserting code at the instruction level of an application, while the application is running, thereby able to accurately profile data-dependent application behavior. Runtime overheads seen from instrumentation, however, can obviate its utility. This paper shows how a combination of information flow analysis and symbolic execution can be used to alleviate these overheads. The methods and their effectiveness are demonstrated for a variety of GPGPU codes written in OpenCL that run on AMD GPU target backends. Kernels that can be analyzed entirely via symbolic execution need not be instrumented, thus eliminating kernel runtime overheads altogether. For the remaining GPU kernels, our results show 5-38% improvements in kernel runtime overheads.",
    "keywords": [
      "OpenCL",
      "CUDA",
      "GPGPU",
      "Rodinia"
    ]
  },
  {
    "title": "CUDA Flux: A Lightweight Instruction Profiler for CUDA Applications",
    "authors": "Lorenz Braun and H. Fr\u00f6ning",
    "year": "2019",
    "doi": "10.1109/PMBS49563.2019.00014",
    "abstract": "GPUs are powerful, massively parallel processors, which require a vast amount of thread parallelism to keep their thousands of execution units busy, and to tolerate latency when accessing its high-throughput memory system. Understanding the behavior of massively threaded GPU programs can be difficult, even though recent GPUs provide an abundance of hardware performance counters, which collect statistics about certain events. Profiling tools that assist the user in such analysis for their GPUs, like NVIDIA's nvprof and cupti, are state-of-the-art. However, instrumentation based on reading hardware performance counters can be slow, in particular when the number of metrics is large. Furthermore, the results can be inaccurate as instructions are grouped to match the available set of hardware counters.",
    "keywords": [
      "GPU",
      "CUDA",
      "LLVM",
      "Profiling",
      "PTX"
    ]
  },
  {
    "title": "Implementing and Evaluating OpenCL on an ARMv8 Multi-Core CPU",
    "authors": "Jianbin Fang and P. Zhang and T. Tang and Chun Huang and Canqun Yang",
    "year": "2017",
    "doi": "10.1109/ISPA/IUCC.2017.00131",
    "abstract": "The OpenCL standard allows targeting a large variety of CPU, GPU and accelerator architectures using a single unified programming interface and language. But guaranteeing portability relies heavily on platform-specific implementations. In this paper, we provide an OpenCL implementation on an ARMv8 multi-core CPU, which efficiently maps the generic OpenCL platform model to the ARMv8 multi-core architecture. With this implementation, we first characterize the maximum achieved arithmetic throughput and memory accessing bandwidth on the architecture, and measure the OpenCL-related overheads. Our results demonstrate that there exists an optimization room for improving OpenCL kernel performance. Then, we compare the performance of OpenCL against serial codes and OpenMP codes with 11 benchmarks. The experimental results show that (1) the OpenCL implementation can achieve an average speedup of 6X compared to its OpenMP counterpart, and (2) the GPU-specified OpenCL codes are often unsuitable for this ARMv8 multi-core CPU.",
    "keywords": [
      "OpenCL",
      "FT-1500A",
      "performance",
      "programming"
    ]
  },
  {
    "title": "COX: CUDA on X86 by Exposing Warp-Level Functions to CPUs",
    "authors": "Ruobing Han and Jaewon Lee and Jaewoong Sim and Hyesoon Kim",
    "year": "2021",
    "doi": "",
    "abstract": "As CUDA programs become the de facto program among data parallel applications such as highperformance computing or machine learning applications, running CUDA on other platforms has been a compelling option. Although several efforts have attempted to support CUDA on other than NVIDIA GPU devices, due to extra steps in the translation, the support is always behind a few years from supporting CUDA\u2019s latest features. The examples are DPC, Hipfy, where CUDA source code have to be translated to their native supporting language and then they are supported. In particular, the new CUDA programming model exposes the warp concept in the programming language, which greatly changes the way the CUDA code should be mapped to CPU programs. In this paper, hierarchical collapsing that correctly supports CUDA warp-level functions on CPUs is proposed. Based on hierarchical collapsing, a framework, COX, is developed that allows CUDA programs with the latest features to be executed efficiently on CPU platforms. COX consists of a compiler IR transformation (new LLVM pass) and a runtime system to execute the transformed programs on CPU devices. COX can support the most recent CUDA features, and the application coverage is much higher (90%) than for previous frameworks (68%) with comparable performance. We also show that the warp-level functions in CUDA can be efficiently executed by utilizing CPU SIMD (AVX) instructions.",
    "keywords": [
      "GPU",
      "code migration",
      "compiler transformations"
    ]
  }
]